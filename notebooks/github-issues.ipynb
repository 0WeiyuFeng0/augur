{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perceval.backends.core.github import GitHub\n",
    "from datetime import date\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlalchemy as s\n",
    "import augur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "augurApp = augur.Application('../augur.config.json')\n",
    "list1,path = augurApp.github_issues()\n",
    "DB_STR = 'mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8'.format(\n",
    "            list1[0], list1[1], list1[2],\\\n",
    "            list1[3], list1[4]\n",
    "        )\n",
    "db = s.create_engine(DB_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"notebooks\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "path = os.getcwd() + '/runtime/git_repos.csv'\n",
    "print(path)\n",
    "if(not os.path.exists(path)):\n",
    "    file = open(path, \"w+\")\n",
    "else:\n",
    "    file = open(path, \"r\")\n",
    "    print(\"yeah\")\n",
    "if (os.stat(path).st_size == 0):\n",
    "    file.write(\"owner,repo_url\\n\")\n",
    "    #file.write(\"nodejs,\\\"CTC\\\"\\n\")\n",
    "    #file.write(\"https://lists.opendaylight.org/pipermail/,\\\"archetypes-dev\\\"\\n\")\n",
    "    print(\"Please enter the mailing lists and the links for them please\")\n",
    "    print(\"Going to the default mailing lists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Url for the git repo to analyze\n",
    "#repo_url = 'https://github.com/chaoss/grimoirelab-perceval'\n",
    "repo_url = 'CTC'\n",
    "# Directory for letting Perceval clone the git repo\n",
    "#repo_dir = 'CTC'\n",
    "token = 'e3f0dd3ccf0174ba4fe351c7c12a275b666f2c34'\n",
    "own = 'nodejs'\n",
    "# ElasticSearch instance (url)\n",
    "#repo = 'grimoirelab-perceval'\n",
    "\n",
    "# Create the 'commits' index in ElasticSearch\n",
    "# Create a Git object, pointing to repo_url, using repo_dir for cloning\n",
    "repo = GitHub(owner=own,repository=repo_url,api_token=token)\n",
    "\n",
    "#32\n",
    "#date = datetime.datetime(2017, 8, 7, 0, 0, 0,\n",
    "#                                     tzinfo=dateutil.tz.tzutc())\n",
    "k=0\n",
    "#for issues in repo.fetch(from_date=date):\n",
    "columns1 = 'augurmsgID',\"backend_name\",'repo_link',\"owner\",\"repo\",\"subject\",\\\n",
    "          \"status\",\"category\",\"issue_number\",\"timestamp\",\\\n",
    "          \"issue_id\",\"user\",\"body\"\n",
    "df = pd.DataFrame(columns=columns1)\n",
    "item = 1\n",
    "df.to_sql(name=\"github_issues\", con=db,\\\n",
    "          if_exists='replace',index=False,\n",
    "           dtype={'augurmsgID': s.types.Integer,#0\n",
    "                  'backend_name': s.types.VARCHAR(length=300),#1\n",
    "                  'repo_link': s.types.VARCHAR(length=300),#2\n",
    "                  'owner': s.types.VARCHAR(length=300),#3\n",
    "                  'repo': s.types.VARCHAR(length=300),#4\n",
    "                  'subject': s.types.VARCHAR(length=300),#5\n",
    "                  'status': s.types.VARCHAR(length=10),#6\n",
    "                  'category': s.types.VARCHAR(length=10),#7\n",
    "                  'issue_number': s.types.Integer,#8\n",
    "                  'timestamp': s.types.Integer,#9\n",
    "                  'issue_id': s.types.Integer,#10\n",
    "                  'user': s.types.VARCHAR(length=100),#11\n",
    "                  'body':s.types.TEXT#12              \n",
    "           })\n",
    "for issues in repo.fetch():\n",
    "    # Create the object (dictionary) to upload to ElasticSearch\n",
    "    # Create the object (dictionary) to upload to ElasticSearch\n",
    "    #if(i==90):\n",
    "    if 'pull_request' in issues['data']:\n",
    "        #print(issues['data']['number'])\n",
    "        continue\n",
    "    else:\n",
    "        #if(issues['data']['state'] == 'closed' and issues['data']\\\n",
    "        #   ['number'] == 165): \n",
    "        text = issues['data']['body']\n",
    "        user = issues['data']['user']['login']\n",
    "        num = issues['data']['number']\n",
    "        id_num = issues['data']['id']\n",
    "        #print(id_num)\n",
    "        store = [item,issues['backend_name'],issues['tag'],own,repo_url,\\\n",
    "                 issues['data']['title'],issues['data']['state'],\\\n",
    "                 issues['category'],num,issues['timestamp'],\\\n",
    "                 id_num,user,text]\n",
    "        #print(store[:])\n",
    "        #print(store[6])\n",
    "        #print(\"Issue number: \",issues['data']['number'])\n",
    "        #if(k > 1):\n",
    "            #k+=1\n",
    "            #continue\n",
    "        '''print(\"Backend_name: \", issues['backend_name'])\n",
    "        print(\"Category: \", issues['category'])\n",
    "        print(\"Subject: \", issues['data']['title'])\n",
    "        print(\"State: \", issues['data']['state'])\n",
    "        print(\"First body:\",issues['data']['body'])\n",
    "        print(\"User: \", issues['data']['user']['login'])\n",
    "        print(\"\\n\\n\\n\")'''\n",
    "        df_user = pd.DataFrame([store],columns=columns1)\n",
    "        df = df.append(df_user)\n",
    "        item+=1\n",
    "        for i in range(len(issues['data']['comments_data'])):\n",
    "            temp=0\n",
    "            store[0] = item\n",
    "            store[8] = issues['data']['number']\n",
    "            store[10] = issues['data']['id']\n",
    "            store[11] = issues['data']['comments_data'][i]\\\n",
    "            ['user_data']['login']\n",
    "            store[12] = issues['data']['comments_data'][i]['body']\n",
    "            df_user = pd.DataFrame([store],columns=columns1)\n",
    "            df = df.append(df_user)\n",
    "            #print(issues['data']['comments_data'][i]\\\n",
    "            #      ['user_data']['login'])\n",
    "            #print(issues['data']['comments_data'][i]['body'])\n",
    "            item+=1\n",
    "          \n",
    "    if(df.shape[0] > 1000):\n",
    "        df.to_sql(name='github_issues', con=db,\\\n",
    "                  if_exists='append',index=False)\n",
    "        df = pd.DataFrame(columns=columns1)\n",
    "        print(\"Broken\")\n",
    "        #break\n",
    "    #print(issues['data'][''])\n",
    "    if(k%50 == 0):\n",
    "        print(k)\n",
    "    k+=1\n",
    "    #if(k == 2):\n",
    "    #    break\n",
    "#print(df)\n",
    "if(df.shape[0] < 1000):\n",
    "    df.to_sql(name='github_issues', con=db,\\\n",
    "                  if_exists='append',index=False)\n",
    "    df = pd.DataFrame(columns=columns1)\n",
    "    print(\"Broken\")\n",
    "print(\"Total Number of issues: \", k)\n",
    "print(df.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (augur)",
   "language": "python",
   "name": "augur"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
